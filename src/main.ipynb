{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Data: Tweets / Weibos #\n",
    "#########################\n",
    "\n",
    "# ENGLISH\n",
    "# https://www.kaggle.com/datasets/tariqsays/sentiment-dataset-with-1-million-tweets // 09/22/2020 - 10/10/2022 // 937854 tweets\n",
    "tweets_kaggle = pd.read_csv(\"data/kaggle-20-22.csv\")\n",
    "tweets_kaggle.drop(columns=[\"Language\", \"Label\"], inplace=True)\n",
    "tweets_kaggle = tweets_kaggle.rename(columns={\"Text\": \"tweet\"})\n",
    "\n",
    "\n",
    "# https://archive.ics.uci.edu/ml/datasets/Health+News+in+Twitterw // 2011-06-13 - 2015-04-09 // 62316 tweets\n",
    "tweets_uci = pd.DataFrame()\n",
    "directory = \"data/uci-2015/\"\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                directory + filename,\n",
    "                sep=\"|\",\n",
    "                header=None,\n",
    "                on_bad_lines=\"skip\",\n",
    "                engine=\"python\",\n",
    "            )\n",
    "        except:\n",
    "            print(\"Error reading file: \" + filename)\n",
    "            assert False\n",
    "        df.columns = [\"tweet_id\", \"date\", \"tweet\"]\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%a %b %d %H:%M:%S %z %Y\")\n",
    "        df[\"date\"] = df[\"date\"].dt.tz_convert(None)\n",
    "        df.drop(columns=[\"tweet_id\"], inplace=True)\n",
    "        tweets_uci = pd.concat([tweets_uci, df])\n",
    "\n",
    "# 1,000,170 tweets in total\n",
    "tweets = pd.concat([tweets_kaggle, tweets_uci])\n",
    "\n",
    "# CHINESE\n",
    "# https://github.com/brightmart/nlp_chinese_corpus, webtext2019zh dataset // 2015 - 2016 // 41,000,000 posts\n",
    "weibo = pd.read_json(\"data/webtext15-16.json\", lines=True)\n",
    "weibo.drop_duplicates(subset=[\"qid\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Data: News Articles #\n",
    "#######################\n",
    "\n",
    "# ENGLISH\n",
    "# https://components.one/datasets/all-the-news-2-news-articles-dataset/ // 2017-08-01 - 2018-02-01 // 2688878 articles\n",
    "en_news = pd.read_csv(\"data/all-the-news.csv\", parse_dates=[\"date\"])\n",
    "# en_news[\"date\"] = pd.to_datetime(en_news[\"date\"], format=\"YYYY-MM-DD HH:MM:SS\")\n",
    "en_news.drop(columns=[\"url\"], inplace=True)\n",
    "\n",
    "# CHINESE\n",
    "# https://www.kaggle.com/datasets/ceshine/yet-another-chinese-news-dataset\n",
    "ch_news = pd.read_csv(\"data/ch-news.csv\", parse_dates=[\"date\"])\n",
    "# ch_news[\"date\"] = pd.to_datetime(ch_news[\"date\"], format=\"YYYYMMDD\")\n",
    "ch_news.drop(columns=[\"url\", \"image\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_news[\"date\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Data: Pre-process #\n",
    "#####################\n",
    "\n",
    "en_keywords = [\n",
    "    \"Alzheimer\",\n",
    "    \"Dementia\",\n",
    "    \"Ageing\",\n",
    "    \"Memory loss\",\n",
    "    \"Cognitive impairment\",\n",
    "    \"Neurodegenerative disease\",\n",
    "    \"Brain health\",\n",
    "    \"Aging population\",\n",
    "    \"Mild cognitive impairment\",\n",
    "    \"Tau protein\",\n",
    "    \"Beta-amyloid protein\",\n",
    "    \"Brain imaging\",\n",
    "    \"Neuropsychological testing\",\n",
    "    \"Caregiving\",\n",
    "    \"Risk factors\",\n",
    "    \"Lifestyle interventions\",\n",
    "    \"Pharmacotherapy\",\n",
    "    \"Rehabilitation\",\n",
    "    \"Social support\",\n",
    "    \"Quality of life\",\n",
    "    \"Long-term care\",\n",
    "    \"Epidemiology\",\n",
    "]\n",
    "\n",
    "if not os.path.exists(\"out\"):\n",
    "    os.makedirs(\"out\")\n",
    "    \n",
    "print(\"Loading English data...\")\n",
    "\n",
    "# Cache filtered tweets\n",
    "if os.path.exists(\"out/relevant_tweets.xlsx\"):\n",
    "    print(\"Loading cached tweets...\")\n",
    "    relevant_tweets = pd.read_excel(\"out/relevant_tweets.xlsx\")\n",
    "else:\n",
    "    # 1987 relevant tweets\n",
    "    print(\"Filtering tweets...\")\n",
    "    relevant_tweets = tweets[\n",
    "        tweets.tweet.str.contains(\"|\".join(en_keywords), case=False, na=False)\n",
    "    ]\n",
    "    relevant_tweets.to_excel(\"out/relevant_tweets.xlsx\", header=True, index=False)\n",
    "\n",
    "\n",
    "# Cache filtered news articles\n",
    "if os.path.exists(\"out/relevant_en_news.xlsx\"):\n",
    "    print(\"Loading cached news articles...\")\n",
    "    relevant_en_news = pd.read_excel(\"out/relevant_en_news.csv\")\n",
    "else:\n",
    "    # 1533 relevant news articles\n",
    "    print(\"Filtering news articles...\")\n",
    "    relevant_en_news = en_news[\n",
    "        en_news.title.str.contains(\"|\".join(en_keywords), case=False, na=False)\n",
    "    ]\n",
    "    relevant_en_news.to_excel(\"out/relevant_en_news.xlsx\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_keywords = [\n",
    "    \"阿尔茨海默\",  # \"Alzheimer\"\n",
    "    \"失智\",  # \"Dementia\"\n",
    "    \"老化\",  # \"Ageing\"\n",
    "    # \"减退\",  # \"Memory loss\"\n",
    "    # \"认知障碍\",  # \"Cognitive impairment\"\n",
    "    \"神经退化\",  # \"Neurodegenerative disease\"\n",
    "    # \"大脑健康\",  # \"Brain health\"\n",
    "    \"人口老龄化\",  # \"Aging population\"\n",
    "    \"轻度认知障碍\",  # \"Mild cognitive impairment\"\n",
    "    \"Tau蛋白\",  # \"Tau protein\"\n",
    "    \"β-淀粉样蛋,\" \"大脑成像\",  # \"Beta-amyloid protein\"  # \"Brain imaging\"\n",
    "    \"神经心理学测试\",  # \"Neuropsychological testing\"\n",
    "    # \"照顾\",  # \"Caregiving\"\n",
    "    # \"风险因素\",  # \"Risk factors\"\n",
    "    # \"遗传\",  # \"Genetics\"\n",
    "    # \"药物\",  # \"Pharmacotherapy\"\n",
    "    # \"康复\",  # \"Rehabilitation\"\n",
    "    # \"社会支持\",  # \"Social support\"\n",
    "    # \"生活质量\",  # \"Quality of life\"\n",
    "    # \"长期护理\",  # \"Long-term care\"\n",
    "]\n",
    "\n",
    "if not os.path.exists(\"out\"):\n",
    "    os.makedirs(\"out\")\n",
    "\n",
    "print(\"Loading Chinese data...\")\n",
    "\n",
    "# Cache filtered tweets\n",
    "if os.path.exists(\"out/relevant_weibo.csv\"):\n",
    "    print(\"Loading cached weibos...\")\n",
    "    relevant_weibo = pd.read_csv(\"out/relevant_weibo.csv\")\n",
    "else:\n",
    "    # 7985 relevant weibos\n",
    "    print(\"Filtering weibos...\")\n",
    "    relevant_weibo = weibo[\n",
    "        weibo.title.str.contains(\"|\".join(ch_keywords), case=False, na=False)\n",
    "        | weibo.desc.str.contains(\"|\".join(ch_keywords), case=False, na=False)\n",
    "    ]\n",
    "    relevant_weibo.to_csv(\"out/relevant_weibo.csv\", header=True, index=False, encoding=\"utf_8_sig\")\n",
    "\n",
    "\n",
    "# Cache filtered news articles\n",
    "if os.path.exists(\"out/relevant_ch_news.csv\"):\n",
    "    print(\"Loading cached news articles...\")\n",
    "    relevant_ch_news = pd.read_csv(\"out/relevant_ch_news.csv\")\n",
    "else:\n",
    "    # 467 relevant news articles\n",
    "    print(\"Filtering news articles...\")\n",
    "    relevant_ch_news = ch_news[\n",
    "        ch_news.title.str.contains(\"|\".join(ch_keywords), case=False, na=False)\n",
    "        | ch_news.desc.str.contains(\"|\".join(ch_keywords), case=False, na=False)\n",
    "    ]\n",
    "    relevant_ch_news.to_csv(\"out/relevant_ch_news.csv\", header=True, index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant_en_news    # 1533 relevant news articles\n",
    "# relevant_tweets     # 1987 relevant tweets\n",
    "# relevant_ch_news    # 204 relevant news articles\n",
    "# relevant_weibo      # 258 relevant weibos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of tweets and news articles over time\n",
    "\n",
    "# Set figure size and title\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Distribution of Dates\")\n",
    "\n",
    "# Create histogram of date column\n",
    "plt.hist(relevant_en_news[\"date\"], bins=10, label=\"English News\")\n",
    "plt.hist(relevant_ch_news[\"date\"], bins=10, label=\"Chinese News\")\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
